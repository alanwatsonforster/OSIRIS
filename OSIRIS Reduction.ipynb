{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "toc-autonumbering": false,
    "toc-showcode": false,
    "toc-showmarkdowntxt": false,
    "toc-showtags": false,
    "colab": {
      "name": "OSIRIS Reduction.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7kTGMKea8ory"
      },
      "source": [
        "# OSIRIS Reduction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9hwaTVtl8ory"
      },
      "source": [
        "This notebook contains functions to reduce GTC/OSIRIS broadband *griz* imaging. \n",
        "\n",
        "There are a number of simplifications:\n",
        "\n",
        "* They only reduce CCD_2.\n",
        "* Lots of constants are hardwired.\n",
        "* They don't do iterative sky subtraction.\n",
        "* They don't do astrometric calibration.\n",
        "\n",
        "However, they have the following advantages:\n",
        "\n",
        "* They can improve the alignment of images using stars.\n",
        "* They can reduce data without using any calibration data files, if necessary.\n",
        "* They can reduce data using old calibration produce files, if neccessary.\n",
        "* They can reduce data using new calibration files.\n",
        "* They are relatively simply to understand, so they are fairly easy to modify for special cases.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PeXsim7J8orz"
      },
      "source": [
        "## About OSIRIS\n",
        "\n",
        "Useful links on OSIRIS include:\n",
        "\n",
        "* [OSIRIS Summary](http://www.gtc.iac.es/instruments/osiris/osiris.php)\n",
        "* [OSIRIS Users Manual](http://www.gtc.iac.es/instruments/osiris/media/OSIRIS-USER-MANUAL_v3_1.pdf)\n",
        "* [CCD44-82 Datasheet](https://www.teledyneimaging.com/download/55de129b-47e1-4fbf-8ad0-98f9aabab995/)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A_keaCBO8orz"
      },
      "source": [
        "## Instructions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VhnEqyig8orz"
      },
      "source": [
        "### Directory Structure\n",
        "\n",
        "We follow the directory structure of the data supplied by GTC in the .tar.gz files. That is, we assume that all of the raw bias, sky flat, and object files are in subdirectories of a top-level directory *topdir* as follows: \n",
        "\n",
        "* *topdir*/bias/ — raw bias files\n",
        "* *topdir*/flat/ — raw flat files\n",
        "* *topdir*/object/ — raw object files\n",
        "\n",
        "We write products to the top-level directory too:\n",
        "\n",
        "* *topdir*/bias.fits — the bias file\n",
        "* *topdir*/flat-*X*.fits — the flat file for the filter *X*\n",
        "* *topdir*/mask-*X*.fits — the mask file for the filter *X*\n",
        "* *topdir*/object-*X*.fits — the object file for the filter *X*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "44zhBvtx8or0"
      },
      "source": [
        "### Reduction with Calibration Data Files\n",
        "\n",
        "The basic recipe to reduce data with calibration data files is as follows. We assume the data are in the *r* filter, but the modification to other filters is obvious.\n",
        "\n",
        "- Make sure the raw data files are organized correctly (see above).\n",
        "\n",
        "- Define a string *topdir* that points to the top-level directory:\n",
        "\n",
        "  topdir='...'\n",
        "\n",
        "- Make a bias:\n",
        "\n",
        "  makebias(topdir)\n",
        "\n",
        "- Make a flat and mask by running, for example:\n",
        "\n",
        "  makeflatandmask(topdir, 'r')\n",
        "       \n",
        "  Repeat this for each filter used.\n",
        "\n",
        "- Make a first coadd, aligning the images using the telescope, by running, for example:\n",
        "\n",
        "  makeobject(topdir, 'r')\n",
        "  \n",
        "  This will produce an object image *TOPDIR*/object-r.fits.\n",
        "       \n",
        "- Display the object image *TOPDIR*/object-r.fits in DS9 and find the coordinates (*X*,*Y*) of an isolated, bright, but unsaturated star. Make a second coadd, aligning on the peak of the star, by running:\n",
        "\n",
        "  makeobject(topdir, 'r', align=(*Y*,*X*))\n",
        "  \n",
        "  Note that the coordinates are specified in the standard NumPy order with *Y* before *X*.\n",
        "\n",
        "- Examine the inline images produced when the previous command is run. Delete any images that have poor PSFs. (Make copies of the data first!)\n",
        "\n",
        "- Produce a final coadd image, aligning on the peak of the star and using only the undeleted images, by running again:\n",
        "\n",
        "  makeobject(topdir, 'r', align=(*Y*,*X*))\n",
        "  \n",
        " - Repeat the *makeobject* steps for each filter used."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UwXVUM5I8or0"
      },
      "source": [
        "### Reductions with Old Calibration Data Files\n",
        "\n",
        "To reduce data with old calibration files, just copy the bias.fits, flat-*X*.fits, and mask-*X*.fits files to the top-level directory and then use the recipe from the first *makeobject* onwards."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FBw19kBw8or0"
      },
      "source": [
        "### Reductions with No Calibration Data Files\n",
        "\n",
        "To reduce data with no calibration files, just use the recipe from the first *makeobject* onwards. The code will assume the bias is all zeros and the flat and mask are all ones, so the results will be ugly. However, sometimes needs must."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Utp91uQ18or0"
      },
      "source": [
        "## Code"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "64H2z2La8or0"
      },
      "source": [
        "### Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k0sk7PLf8or1"
      },
      "source": [
        "import glob\n",
        "import math\n",
        "import os.path\n",
        "\n",
        "import astropy.io.fits\n",
        "import astropy.stats\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import scipy.ndimage"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rux8MFq48or1"
      },
      "source": [
        "### Warnings\n",
        "\n",
        "Without the following, we get lots for warnings about NaNs."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KVyhLVb58or1"
      },
      "source": [
        "import sys\n",
        "\n",
        "if not sys.warnoptions:\n",
        "    import warnings\n",
        "\n",
        "    warnings.simplefilter(\"ignore\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "frtkjlX88or1"
      },
      "source": [
        "### Selecting FITS Files\n",
        "\n",
        "The *getfitspaths* function returns a list of the paths of the FITS files in the directory *directorypath*. If the *filter* keyword argument is specified (as 'g', 'r', 'i', or 'z'), it returns only those taken in the specified filter."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "id": "EesdGRFf8or1"
      },
      "source": [
        "def getfitspaths(directorypath, filter=None):\n",
        "    fitspaths = sorted(glob.glob(directorypath + \"/*.fits\"))\n",
        "    if filter == None:\n",
        "        return fitspaths\n",
        "    else:\n",
        "        return list(\n",
        "            fitspath\n",
        "            for fitspath in fitspaths\n",
        "            if astropy.io.fits.open(fitspath)[0].header[\"FILTER2\"]\n",
        "            == (\"Sloan_\" + filter)\n",
        "        )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HvzwQSR88or1"
      },
      "source": [
        "### Reading and Writing FITS Files.\n",
        "\n",
        "The *readbias*, *readflat*, and *readmask* functions read the bias, flat, and mask files from the specified directory. If they are not found, then rough approximations are generated by the appropriate *makefake...* functions.\n",
        "\n",
        "The *writebias*, *writeflat*, *writemask*, and *writeobject* functions write bias, flat, mask, and object files to the specified directory."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "id": "LXbhjMAV8or1"
      },
      "source": [
        "def readbias(directorypath, name=\"readbias\"):\n",
        "    global _biasdata\n",
        "    path = directorypath + \"/bias.fits\"\n",
        "    if os.path.exists(path):\n",
        "        print(\"%s: reading bias.fits\" % (name))\n",
        "        _biasdata = astropy.io.fits.open(path)[0].data\n",
        "    else:\n",
        "        print(\"%s: WARNING: no bias found; using a fake bias.\" % (name))\n",
        "        makefakebias()\n",
        "    return _biasdata\n",
        "\n",
        "\n",
        "def readflat(directorypath, filter, name=\"readflat\"):\n",
        "    global _flatdata\n",
        "    path = directorypath + (\"/flat-%s.fits\" % filter)\n",
        "    if os.path.exists(path):\n",
        "        print(\"%s: reading flat-%s.fits\" % (name, filter))\n",
        "        _flatdata = astropy.io.fits.open(path)[0].data\n",
        "    else:\n",
        "        print(\"%s: WARNING: no flat found; using a fake flat.\" % (name))\n",
        "        makefakeflat()\n",
        "    return _flatdata\n",
        "\n",
        "\n",
        "def readmask(directorypath, filter, name=\"readmask\"):\n",
        "    global _maskdata\n",
        "    path = directorypath + (\"/mask-%s.fits\" % filter)\n",
        "    if os.path.exists(path):\n",
        "        print(\"%s: reading mask-%s.fits\" % (name, filter))\n",
        "        _maskdata = astropy.io.fits.open(path)[0].data\n",
        "    else:\n",
        "        print(\"%s: WARNING: no mask found; using a fake mask.\" % (name))\n",
        "        makefakemask()\n",
        "    return _maskdata\n",
        "\n",
        "\n",
        "def writebias(directorypath, data, name=\"writebias\"):\n",
        "    print(\"%s: writing bias.fits\" % (name))\n",
        "    global _biasdata\n",
        "    _biasdata = data\n",
        "    astropy.io.fits.PrimaryHDU(data).writeto(\n",
        "        directorypath + \"/bias.fits\", overwrite=True\n",
        "    )\n",
        "    return\n",
        "\n",
        "\n",
        "def writeflat(directorypath, data, filter, name=\"writeflat\"):\n",
        "    print(\"%s: writing flat-%s.fits\" % (name, filter))\n",
        "    global _flatdata\n",
        "    _flatdata = data\n",
        "    astropy.io.fits.PrimaryHDU(data).writeto(\n",
        "        directorypath + (\"/flat-%s.fits\" % filter), overwrite=True\n",
        "    )\n",
        "    return\n",
        "\n",
        "\n",
        "def writemask(directorypath, data, filter, name=\"writemask\"):\n",
        "    print(\"%s: writing mask-%s.fits\" % (name, filter))\n",
        "    global _maskdata\n",
        "    _maskdata = data\n",
        "    astropy.io.fits.PrimaryHDU(data).writeto(\n",
        "        directorypath + (\"/mask-%s.fits\" % filter), overwrite=True\n",
        "    )\n",
        "    return\n",
        "\n",
        "\n",
        "def writeobject(directorypath, data, filter, name=\"writeobject\"):\n",
        "    print(\"%s: writing object-%s.fits\" % (name, filter))\n",
        "    global _objectdata\n",
        "    _objectdata = data\n",
        "    astropy.io.fits.PrimaryHDU(data).writeto(\n",
        "        directorypath + (\"/object-%s.fits\" % filter), overwrite=True\n",
        "    )\n",
        "    return"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2oD8afx_8or2"
      },
      "source": [
        "### CCD Geometry\n",
        "\n",
        "The CCD (when binned 2x2) formally has:\n",
        "\n",
        "* 1049 columns (25 overscan columns followed by 1024 active columns)\n",
        "* 2051 rows\n",
        "\n",
        "We are reject the outer border of active pixels, as they show unusual behaviour."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_II_PnAb8or2"
      },
      "source": [
        "overscanyslice = slice(4, 2051)\n",
        "overscanxslice = slice(2, 22)\n",
        "\n",
        "trimyslice = slice(3, 2048)\n",
        "trimxslice = slice(28, 1046)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pKlb7wDC8or2"
      },
      "source": [
        "### Cooking Raw Data\n",
        "\n",
        "The *cook* procedure is the heart of the reduction functions. It reads a raw file, and then 'cooks' it according to the keyword parameters. In full, the steps are:\n",
        "\n",
        "- Read the data of CCD 2 from the FITS file.\n",
        "\n",
        "- Convert the data to 32-bit floats.\n",
        "\n",
        "- Set saturated values to NaN.\n",
        "\n",
        "- If *dooverscan* is *True*, determine and subtract the overscan level.\n",
        "\n",
        "- If *dotrim* is *True*, trim the data to the active pixels.\n",
        "\n",
        "- If *dobias* is *True*, subtract the redidual bias.\n",
        "\n",
        "- If *doflat* is *True*, divide by the flat.\n",
        "\n",
        "- If *domask* is *True*, set masked pixels to NaN.\n",
        "\n",
        "- If *dosky* is *True*, subtract the median on a column-by-column and then row-by-row basis.\n",
        "\n",
        "- If *donormalize* is *True*, divide by the median.\n",
        "\n",
        "If they are needed, the bias, flat, and mask should have been previously read using *readbias*, *readflat*, and *readmask*."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "id": "nNKPJpgo8or2"
      },
      "source": [
        "def cook(\n",
        "    fitspath,\n",
        "    name=\"cook\",\n",
        "    dooverscan=False,\n",
        "    dotrim=False,\n",
        "    dobias=False,\n",
        "    doflat=False,\n",
        "    donormalize=False,\n",
        "    domask=False,\n",
        "    dosky=False,\n",
        "):\n",
        "\n",
        "    print(\"%s: reading file %s.\" % (name, os.path.basename(fitspath)))\n",
        "    data = np.array(astropy.io.fits.open(fitspath)[2].data, dtype=np.float32)\n",
        "\n",
        "    # Set saturated pixels to nan.\n",
        "    data[np.where(data == (2 ** 16 - 1))] = np.nan\n",
        "\n",
        "    if dooverscan:\n",
        "        # Converted from BIASSEC.\n",
        "        overscandata = data[overscanyslice, overscanxslice]\n",
        "        mean, median, sigma = astropy.stats.sigma_clipped_stats(overscandata, sigma=3)\n",
        "        print(\"%s: removing overscan level of %.2f ± %.2f DN.\" % (name, mean, sigma))\n",
        "        data -= mean\n",
        "\n",
        "    if dotrim:\n",
        "        # Converted from DATASEC.\n",
        "        print(\"%s: trimming.\" % (name))\n",
        "        data = data[trimyslice, trimxslice]\n",
        "\n",
        "    if dobias:\n",
        "        print(\"%s: subtracting bias.\" % (name))\n",
        "        data -= _biasdata\n",
        "\n",
        "    if doflat:\n",
        "        print(\"%s: dividing by flat.\" % (name))\n",
        "        data /= _flatdata\n",
        "\n",
        "    if domask:\n",
        "        print(\"%s: masking.\" % (name))\n",
        "        data[np.where(_maskdata == 0)] = np.nan\n",
        "\n",
        "    median = np.nanmedian(data)\n",
        "    print(\"%s: median is %.1f DN.\" % (name, median))\n",
        "\n",
        "    if dosky:\n",
        "        print(\"%s: subtracting sky.\" % (name))\n",
        "        data -= np.nanmedian(data, axis=0, keepdims=True)\n",
        "        data -= np.nanmedian(data, axis=1, keepdims=True)\n",
        "\n",
        "    if donormalize:\n",
        "        print(\"%s: normalizing to median.\" % (name))\n",
        "        data /= median\n",
        "\n",
        "    return data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B28rzY_48or2"
      },
      "source": [
        "### Making Fake Biases, Flats, and Masks.\n",
        "\n",
        "We sometimes need to reduce data without calibration files. The *makefakebias*, *makefakeflat*, and *makefakemask* functions generate rough approximations: all zeros for biases and all ones for the flats and masks."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B_qlwadu8or3"
      },
      "source": [
        "def makefakebias():\n",
        "    global _biasdata\n",
        "    _biasdata = np.zeros((2051, 1024))\n",
        "    return _biasdata\n",
        "\n",
        "\n",
        "def makefakeflat():\n",
        "    global _flatdata\n",
        "    _flatdata = np.ones((2051, 1024))\n",
        "    return _flatdata\n",
        "\n",
        "\n",
        "def makefakemask():\n",
        "    global _maskdata\n",
        "    _maskdata = np.ones((2051, 1024))\n",
        "    return _maskdata"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n7UQ8SIo8or3"
      },
      "source": [
        "### Making Residual Bias Files\n",
        "\n",
        "The *makebias* function makes the residual bias file bias.fits from the bias images in the subdirectory bias/.\n",
        "\n",
        "To make the residual bias, it:\n",
        "- Subtracts the overscan.\n",
        "- Trims the image to the active pixels.\n",
        "- Determines the mean of the stack with 3-sigma rejection and using the [MAD](https://docs.astropy.org/en/stable/api/astropy.stats.mad_std.html#astropy.stats.mad_std) to robustly estimate sigma.\n",
        "- Plots the median of the columns and rows.\n",
        "- Writes the mean to bias.fits."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "id": "LRZEwbOs8or3"
      },
      "source": [
        "def makebias(directorypath):\n",
        "    def readonebias(fitspath):\n",
        "        return cook(fitspath, name=\"makebias\", dooverscan=True, dotrim=True)\n",
        "\n",
        "    print(\"makebias: making bias.fits from %s.\" % (directorypath))\n",
        "\n",
        "    fitspathlist = getfitspaths(directorypath + \"/bias/\")\n",
        "    if len(fitspathlist) == 0:\n",
        "        print(\"ERROR: no bias files found.\")\n",
        "        return\n",
        "\n",
        "    datalist = list(readonebias(fitspath) for fitspath in fitspathlist)\n",
        "\n",
        "    if len(datalist) == 0:\n",
        "        print(\"ERROR: no bias files found.\")\n",
        "        return\n",
        "\n",
        "    print(\"makebias: averaging %d biases with rejection.\" % len(datalist))\n",
        "    mean, median, sigma = astropy.stats.sigma_clipped_stats(\n",
        "        datalist, sigma=3, axis=0, stdfunc=astropy.stats.mad_std\n",
        "    )\n",
        "    biasdata = mean\n",
        "\n",
        "    mean, median, sigma = astropy.stats.sigma_clipped_stats(biasdata, sigma=5)\n",
        "    print(\"makebias: final residual bias level is %.2f ± %.2f DN.\" % (mean, sigma))\n",
        "\n",
        "    print(\"makebias: plotting median of columns.\")\n",
        "    plt.figure()\n",
        "    plt.plot(range(biasdata.shape[1]), np.nanmedian(biasdata, axis=0))\n",
        "    plt.show()\n",
        "    print(\"makebias: plotting median of rows.\")\n",
        "    plt.figure()\n",
        "    plt.plot(range(biasdata.shape[0]), np.nanmedian(biasdata, axis=1))\n",
        "    plt.show()\n",
        "\n",
        "    writebias(directorypath, biasdata, name=\"makebias\")\n",
        "\n",
        "    print(\"makebias: finished.\")\n",
        "\n",
        "    return"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2Fd51kgY8or3"
      },
      "source": [
        "### Making Flat and Mask Files\n",
        "\n",
        "The *makeflatandmask* function makes the flat and mask files flat-*X*.fits and mask-*X*.fits for the given filter *X* from the sky flat images in the subdirectory flat/.\n",
        "\n",
        "To make the flat, it:\n",
        "- Subtracts the overscan.\n",
        "- Trims the image to the active pixels.\n",
        "- Subtracts the residual bias.\n",
        "- Masks pixels\n",
        "- Normalizes to the median.\n",
        "- Determines the mean of the stack with 3-sigma rejection and using the [MAD](https://docs.astropy.org/en/stable/api/astropy.stats.mad_std.html#astropy.stats.mad_std) to robustly estimate sigma.\n",
        "- Writes the flat to flat-*X*.fits.\n",
        "\n",
        "The flat is made twice; once with a fake mask with no masked pixels (all ones) and then once again with the real mask. This is because initially we do not necessarily have a real mask.\n",
        "\n",
        "The make the mask (from the first flat), it:\n",
        "- Masks NaNs and Infs.\n",
        "- Masks globally low pixels.\n",
        "- Masks locally low or high pixels.\n",
        "- Masks any pixel that is the neighbor of least two pixels that were masked in the previous steps.\n",
        "- Writes the mask to mask-*X*.fits."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "id": "Z53oovm68or3"
      },
      "source": [
        "def makeflatandmask(directorypath, filter):\n",
        "    def readoneflat(fitspath):\n",
        "        return cook(\n",
        "            fitspath,\n",
        "            name=\"makeflatandmask\",\n",
        "            dooverscan=True,\n",
        "            dotrim=True,\n",
        "            dobias=True,\n",
        "            domask=True,\n",
        "            donormalize=True,\n",
        "        )\n",
        "\n",
        "    def makeflathelper():\n",
        "        datalist = list(readoneflat(fitspath) for fitspath in fitspathlist)\n",
        "        print(\"makeflatandmask: averaging %d flats with rejection.\" % (len(datalist)))\n",
        "        mean, median, sigma = astropy.stats.sigma_clipped_stats(\n",
        "            datalist, sigma=3, axis=0, stdfunc=astropy.stats.mad_std\n",
        "        )\n",
        "        flatdata = mean\n",
        "        return flatdata\n",
        "\n",
        "    def makemaskhelper(flatdata):\n",
        "\n",
        "        maskdata = np.ones(flatdata.shape)\n",
        "\n",
        "        print(\"makeflatandmask: masking nan values.\")\n",
        "        maskdata[np.isnan(flatdata)] = 0\n",
        "\n",
        "        print(\"makeflatandmask: masking inf values.\")\n",
        "        maskdata[np.isinf(flatdata)] = 0\n",
        "\n",
        "        print(\"makeflatandmask: masking globally low pixels.\")\n",
        "        maskdata[np.where(flatdata < 0.80)] = 0\n",
        "\n",
        "        print(\"makeflatandmask: masking locally high or low pixels.\")\n",
        "        low = scipy.ndimage.median_filter(flatdata, 7)\n",
        "        high = flatdata / low\n",
        "        maskdata[np.where(high < 0.97)] = 0\n",
        "        maskdata[np.where(high > 1.03)] = 0\n",
        "\n",
        "        print(\"makeflatandmask: masking pixels with at least two masked neighbors.\")\n",
        "        # Grow the mask so that any pixel with at least 2 neigboring bad pixels is also bad.\n",
        "        grow = scipy.ndimage.filters.uniform_filter(maskdata, size=3, mode=\"nearest\")\n",
        "        maskdata[np.where(grow <= 7 / 9)] = 0\n",
        "\n",
        "        print(\n",
        "            \"makeflatandmask: fraction of masked pixels is %.4f.\"\n",
        "            % (1 - np.nanmean(maskdata))\n",
        "        )\n",
        "\n",
        "        return maskdata\n",
        "\n",
        "    print(\"makeflatandmask: making %s flat from %s.\" % (filter, directorypath))\n",
        "\n",
        "    fitspathlist = getfitspaths(directorypath + \"/flat/\", filter=filter)\n",
        "    if len(fitspathlist) == 0:\n",
        "        print(\"ERROR: no flat files found.\")\n",
        "        return\n",
        "\n",
        "    readbias(directorypath, name=\"makeflatandmask\")\n",
        "\n",
        "    print(\"makeflatandmask: making fake mask.\")\n",
        "    makefakemask()\n",
        "\n",
        "    print(\"makeflatandmask: making flat with fake mask.\")\n",
        "    flatdata = makeflathelper()\n",
        "\n",
        "    print(\"makeflatandmask: making real mask.\")\n",
        "    maskdata = makemaskhelper(flatdata)\n",
        "\n",
        "    writemask(directorypath, maskdata, filter, name=\"makeflatandmask\")\n",
        "\n",
        "    readmask(directorypath, filter, name=\"makeflatandmask\")\n",
        "\n",
        "    print(\"makeflatandmask: making flat with real mask.\")\n",
        "    flatdata = makeflathelper()\n",
        "\n",
        "    writeflat(directorypath, flatdata, filter, name=\"makeflatandmask\")\n",
        "\n",
        "    print(\"makeflatandmask: plotting median of columns.\")\n",
        "    plt.figure()\n",
        "    plt.plot(range(flatdata.shape[1]), np.nanmedian(flatdata, axis=0))\n",
        "    plt.show()\n",
        "    print(\"makeflatandmask: plotting median of rows.\")\n",
        "    plt.figure()\n",
        "    plt.plot(range(flatdata.shape[0]), np.nanmedian(flatdata, axis=1))\n",
        "    plt.show()\n",
        "\n",
        "    print(\"makeflatandmask: finished.\")\n",
        "\n",
        "    return"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q7CfQS0K8or3"
      },
      "source": [
        "### Making Object Files\n",
        "\n",
        "The *makeobject* function reduces, sky-subtracts, aligns, and coadds object images for the given filter *X* from the images in the subdirectory object/ and writes the result to object-*X*.fits.\n",
        "\n",
        "To make the object, it:\n",
        "- Subtracts the overscan.\n",
        "- Trims the image to the active pixels.\n",
        "- Subtracts the residual bias.\n",
        "- Masks pixels\n",
        "- Subtracts the median first column-by-column and then row-by-row.\n",
        "- Shifts the images into a common alignment and pads them with a margin. This is discussed below.\n",
        "- Determines the mean of the stack with 3-sigma rejection and using the [MAD](https://docs.astropy.org/en/stable/api/astropy.stats.mad_std.html#astropy.stats.mad_std) to robustly estimate sigma.\n",
        "- Writes the mean to object-*X*.fits.\n",
        "\n",
        "There are two options for alignment. \n",
        "\n",
        "- If no align keyword argument is given, the relative shifts between images are estimated from the telescope pointing in the headers. These typically have errors of order one arcsec.\n",
        "\n",
        "- If the align keyword argument is given, it must be a a list (*Y*,*X*) giving pixel coordinate in object-*X*.fits file. The code extracts a subregion around this coordinate (taking into account the approximate relative shifts from the headers), finds the maximum, and refines the relative shift using the position of the maximum. The intent is that the coordinates should be those of a bright, unsaturated, isolated star.\n",
        "\n",
        "  The size of the extracted region is determined by the nalignregion keyword argument. The default value is 40 (giving an 10 arcsec region). If the pointing is poor, the alignment star may fall outside the extracted region, and this can be countered by increasing the size.\n",
        "  \n",
        "The intent is that you should produce an initial object file by running *makeobject* without an align keyword argment, display the image in DS9, find the coordinates of an alignment star, and then produce a refined object file by running *makeobject* with the align keyword specifying the coordinates of the alignment star.\n",
        "\n",
        "There are two options for determining the reference position for the alignment.\n",
        "\n",
        "- If either the refalpha or refdelta keyword arguments are None, the code determines it as the average of the maximum and minimum values of alpha and delta of the telescope pointing. This is intended to be robust to individual files being removed.\n",
        "\n",
        "- If both the refalpha and refdelta keyword arguments are numbers, they are interpreted as radians specifying the reference position. To use degrees, write refalpha=math.radians(...) and refdelta=math.radians(...).\n",
        "\n",
        "Normally, it is not necessary to specify explicitly the reference positions.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "id": "NJDh6JpV8or3"
      },
      "source": [
        "def makeobject(\n",
        "    directorypath, filter, align=None, nalignregion=40, refalpha=None, refdelta=None\n",
        "):\n",
        "    def readonepointing(fitspath):\n",
        "        hdu = astropy.io.fits.open(fitspath)\n",
        "        print(\n",
        "            \"makeobject: reading pointing for %s object file %s.\"\n",
        "            % (filter, os.path.basename(fitspath))\n",
        "        )\n",
        "        alpha = math.radians(hdu[0].header[\"RADEG\"])\n",
        "        delta = math.radians(hdu[0].header[\"DECDEG\"])\n",
        "        print(\n",
        "            \"makeobject: pointing is alpha = %.5f deg delta = %.5f deg.\"\n",
        "            % (math.degrees(alpha), math.degrees(delta))\n",
        "        )\n",
        "        return [alpha, delta]\n",
        "\n",
        "    def readoneobject(fitspath):\n",
        "\n",
        "        print(\n",
        "            \"makeobject: reading %s object file %s.\"\n",
        "            % (filter, os.path.basename(fitspath))\n",
        "        )\n",
        "\n",
        "        data = cook(\n",
        "            fitspath,\n",
        "            name=\"makeobject\",\n",
        "            dooverscan=True,\n",
        "            dotrim=True,\n",
        "            dobias=True,\n",
        "            doflat=True,\n",
        "            domask=True,\n",
        "            dosky=True,\n",
        "        )\n",
        "\n",
        "        hdu = astropy.io.fits.open(fitspath)\n",
        "\n",
        "        alpha = math.radians(hdu[0].header[\"RADEG\"])\n",
        "        delta = math.radians(hdu[0].header[\"DECDEG\"])\n",
        "        print(\n",
        "            \"makeobject: pointing is alpha = %.5f deg delta = %.5f deg.\"\n",
        "            % (math.degrees(alpha), math.degrees(delta))\n",
        "        )\n",
        "        dx = +int(np.round((alpha - refalpha) / scale * math.cos(refdelta)))\n",
        "        dy = -int(np.round((delta - refdelta) / scale))\n",
        "        print(\"makeobject: raw offset is dx = %+d px dy = %+d px.\" % (dx, dy))\n",
        "\n",
        "        margin = 100\n",
        "        if align != None:\n",
        "            aligny = align[0] - margin\n",
        "            alignx = align[1] - margin\n",
        "            alignxlo = alignx + dx - nalignregion // 2\n",
        "            alignxhi = alignx + dx + nalignregion // 2\n",
        "            alignylo = aligny + dy - nalignregion // 2\n",
        "            alignyhi = aligny + dy + nalignregion // 2\n",
        "\n",
        "            aligndata = data[alignylo:alignyhi, alignxlo:alignxhi].copy()\n",
        "            aligndata -= np.nanmedian(aligndata)\n",
        "            aligndata = np.nan_to_num(aligndata, nan=0.0)\n",
        "            max = np.unravel_index(np.argmax(aligndata, axis=None), aligndata.shape)\n",
        "            ddy = max[0] - nalignregion // 2\n",
        "            ddx = max[1] - nalignregion // 2\n",
        "            print(\n",
        "                \"makeobject: maximum is offset by ddx = %+d px ddy = %+d px.\"\n",
        "                % (ddx, ddy)\n",
        "            )\n",
        "            dx += ddx\n",
        "            dy += ddy\n",
        "            print(\"makeobject: refined offset is dx = %+d px dy = %+d px.\" % (dx, dy))\n",
        "            plt.figure()\n",
        "            plt.imshow(aligndata, origin=\"lower\")\n",
        "            plt.show()\n",
        "\n",
        "        datashape = np.array(data.shape)\n",
        "        newdata = np.full(datashape + 2 * margin, np.nan, dtype=float)\n",
        "        xlo = margin - dx\n",
        "        xhi = xlo + datashape[1]\n",
        "        ylo = margin - dy\n",
        "        yhi = ylo + datashape[0]\n",
        "        newdata[ylo:yhi, xlo:xhi] = data\n",
        "        data = newdata\n",
        "\n",
        "        return data\n",
        "\n",
        "    scale = math.radians(0.254 / 3600)\n",
        "\n",
        "    print(\"makeobject: making %s object from %s.\" % (filter, directorypath))\n",
        "\n",
        "    fitspathlist = getfitspaths(directorypath + \"/object/\", filter=filter)\n",
        "    if len(fitspathlist) == 0:\n",
        "        print(\"ERROR: no object files found.\")\n",
        "        return\n",
        "\n",
        "    readbias(directorypath, name=\"makeobject\")\n",
        "    readflat(directorypath, filter, name=\"makeobject\")\n",
        "    readmask(directorypath, filter, name=\"makeobject\")\n",
        "\n",
        "    if refalpha == None or refdelta == None:\n",
        "        print(\"makeobject: determining reference pointing.\")\n",
        "        pointinglist = list(readonepointing(fitspath) for fitspath in fitspathlist)\n",
        "        refpointing = (np.max(pointinglist, axis=0) + np.min(pointinglist, axis=0)) / 2\n",
        "        refalpha = refpointing[0]\n",
        "        refdelta = refpointing[1]\n",
        "    print(\n",
        "        \"makeobject: reference pointing is alpha = %.5f deg delta = %.5f deg.\"\n",
        "        % (math.degrees(refalpha), math.degrees(refdelta))\n",
        "    )\n",
        "\n",
        "    datalist = list(readoneobject(fitspath) for fitspath in fitspathlist)\n",
        "\n",
        "    print(\"makeobject: averaging %d object files with rejection.\" % len(datalist))\n",
        "    mean, median, sigma = astropy.stats.sigma_clipped_stats(\n",
        "        datalist, sigma=3, axis=0, stdfunc=astropy.stats.mad_std\n",
        "    )\n",
        "    object = mean\n",
        "\n",
        "    writeobject(directorypath, object, filter, name=\"makeobject\")\n",
        "\n",
        "    print(\"makeobject: finished.\")\n",
        "\n",
        "    return object"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hsb6TOv99FJQ"
      },
      "source": [
        "### Access to Files in Google Drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sRxYTSPa9eaP",
        "outputId": "3d949684-0cfd-4c68-eacd-deddd6fb35f9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_eG5zyVN8or4"
      },
      "source": [
        "## Examples"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "tags": [],
        "id": "_AB_rhf78or4"
      },
      "source": [
        "### 2021-07-06\n",
        "\n",
        "To run an example reduction of the data from 2021-07-06, download the data as described below, change *False* to *True* in the next code block, and run the approriate code blocks."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0cU8hcuM8or4"
      },
      "source": [
        "run_example_20210706 = False"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-3t9-4O68or4"
      },
      "source": [
        "#### Download Data\n",
        "\n",
        "These instructions apply to a Mac. Minor variations might be needed on Linux.\n",
        "\n",
        "The data are available as a compressed tar file on my Google Drive [here](https://drive.google.com/file/d/1tqfIjDeyjkcSUggH1Guq-AEE2gu3AamU/view?usp=sharing). Download the file, then run\n",
        "\n",
        "    (cd ~/Downloads; tar -xf GTCMULTIPLE2B-21AMEX.OB0001.tar)\n",
        "\n",
        "This will unpack the data into /tmp/GTCMULTIPLE2B-21AMEX/OB0001/."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "tags": [],
        "id": "k0dOQpMz8or4"
      },
      "source": [
        "#### Calibration products"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "id": "L33mDmLh8or4"
      },
      "source": [
        "if run_example_20210706:\n",
        "    topdir = os.path.expanduser(\"~/Downloads/GTCMULTIPLE2B-21AMEX/OB0001/\")\n",
        "    makebias(topdir)\n",
        "    makeflatandmask(topdir, \"r\")\n",
        "    makeflatandmask(topdir, \"z\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zHYlpqAw8or4"
      },
      "source": [
        "#### Objects"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "id": "q0RazXN_8or4"
      },
      "source": [
        "if run_example_20210706:\n",
        "    topdir = os.path.expanduser(\"~/Downloads/GTCMULTIPLE2B-21AMEX/OB0001/\")\n",
        "    # makeobject(topdir,'r')\n",
        "    makeobject(topdir, \"r\", align=(1180, 655))\n",
        "    makeobject(topdir, \"z\", align=(1180, 655))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HgtEACUZ8or4"
      },
      "source": [
        "### 2021-07-09\n",
        "\n",
        "To run an example reduction of the data from 2021-07-09, download the data as described below, change *False* to *True* in the next code block, and run the approriate code blocks."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lpcyOIA88or5"
      },
      "source": [
        "run_example_20210709 = False"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XPFFZ9LW8or5"
      },
      "source": [
        "#### Download Data\n",
        "\n",
        "These instructions apply to a Mac. Minor variations might be needed on Linux.\n",
        "\n",
        "The data are available as a compressed tar file on my Google Drive [here](https://drive.google.com/file/d/15aCscuVbK-Io_flW23TT3FeV9dEU8e56/view?usp=sharing). Download the file, then run\n",
        "\n",
        "    (cd ~/Downloads; tar -xf GTCMULTIPLE2B-21AMEX.OB0004.tar)\n",
        "\n",
        "This will unpack the data into /tmp/GTCMULTIPLE2B-21AMEX/OB0004/."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "csfq7Bd28or5"
      },
      "source": [
        "#### Calibration Products"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HnIspwlD8or5"
      },
      "source": [
        "if run_example_20210709:\n",
        "    topdir = os.path.expanduser(\"~/Downloads/GTCMULTIPLE2B-21AMEX/OB0004/\")\n",
        "    makebias(topdir)\n",
        "    makeflatandmask(topdir, \"r\")\n",
        "    makeflatandmask(topdir, \"z\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f360xS2z8or5"
      },
      "source": [
        "#### Objects"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "id": "HlxoKRUq8or5"
      },
      "source": [
        "if run_example_20210709:\n",
        "    topdir = os.path.expanduser(\"~/Downloads/GTCMULTIPLE2B-21AMEX/OB0004/\")\n",
        "    # makeobject(topdir, \"r\")\n",
        "    makeobject(topdir, \"r\", align=(1165, 665))\n",
        "    makeobject(topdir, \"z\", align=(1165, 665))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}